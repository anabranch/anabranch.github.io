<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Getting Started with Apache Spark - Part 1</title>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="/css/normalize.css">
        <link rel="stylesheet" href="/css/skeleton.css">

        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/css/github.css">

        <!-- Custom CSS -->
        <link rel="stylesheet" href="/css/main.css">

    </head>
    <body>

        <div class="container">
              <div class="row">
   <div class="twelve columns personal-intro">
      <h2>The Portfolio & Writings of Bill Chambers</h2>
   </div>
</div>
<div class="row">
   <div class="one offset-by-three columns nav-blocks">
      <a onmouseover="vis_on('hhm');" onmouseout="vis_off('hhm');" href="/"><i class="mdi mdi-home"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hab');" onmouseout="vis_off('hab');" href="/about.html"><i class="mdi mdi-account"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hes');" onmouseout="vis_off('hes');" href="/essays.html"><i class="mdi mdi-file-document"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hpr');" onmouseout="vis_off('hpr');" href="/projects.html"><i class="mdi mdi-beaker"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('htu');" onmouseout="vis_off('htu');" href="/tutorials.html"><i class="mdi mdi-cog"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hem');" onmouseout="vis_off('hem');" href="mailto:wchambers@ischool.berkeley.edu"><i class="mdi mdi-email"></i></a>
   </div>
</div>
<div class="row">
   <div class="one offset-by-three columns nav-blocks">
      <a onmouseover="vis_on('hhm');" onmouseout="vis_off('hhm');" id='hhm' class='sibling' href="/">home</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hab');" onmouseout="vis_off('hab');" id='hab' class='sibling' href="/about.html">about</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hes');" onmouseout="vis_off('hes');" id='hes' class='sibling' href="/essays.html">essays</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hpr');" onmouseout="vis_off('hpr');" id='hpr' class='sibling' href="/projects.html">projects</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('htu');" onmouseout="vis_off('htu');" id='htu' class='sibling' href="/tutorials.html">tutorials</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hem');" onmouseout="vis_off('hem');" id='hem' class='sibling' href="mailto:wchambers@ischool.berkeley.edu">email</a>
   </div>
</div>

              <div class="row">
   <div class="ten offset-by-one columns">
      <article class="post">
         <div class='titles'>
            <h4>Getting Started with Apache Spark - Part 1</h4>
            <p class="meta">
               <!-- <span class='tags'>
                  Tags:
                  
                  
                  </span> -->
               <span class='date'>
               06 December 2014
               </span>
            </p>
         </div>
         <p>Lately I&#39;ve been playing around with <a href="https://spark.apache.org/">Spark</a> for data processing. It provides some really amazing features like <a href="https://spark.apache.org/mllib/">MLLib</a> and <a href="https://spark.apache.org/sql/">Spark SQL</a> and there&#39;s no better way to learn something that to use it. I&#39;ve attended a couple of meet ups about Spark and its related tools including the famous <a href="http://ampcamp.berkeley.edu/">ampcamp</a> put on by the developers of spark and, although I&#39;m not an expert, I thought it would be good to consolidate my knowledge and teach others.</p>

<h2>The Problem Spark Solves</h2>

<p>I always like to best understand the problem that is being solved when I approach new tools. To throw some buzzwords around, you&#39;re looking to perform some data science on some big data. More simply, you&#39;ve got a ton of information that you want to understand more about and doing it on your computer would just be too slow. </p>

<p>Some great examples of data problems that are solved well by a tool like Apache Spark include:</p>

<ol>
<li>Analyzing Log Data

<ul>
<li>In order to hunt down a bug happening on a production server(s)</li>
</ul></li>
<li>Massive Natural Language Processing

<ul>
<li>Finally some use for all that twitter data you&#39;ve been downloading...</li>
</ul></li>
<li>Large Scale Recommendation Systems or General Machine Learning Tasks

<ul>
<li>Recommending products to users or trying to find related groups</li>
</ul></li>
</ol>

<p>While this is far from an exhaustive list, it gives a starting point to the problem we&#39;re solving: we&#39;ve got a ton of information and we want to (actionable) extract information from it.</p>

<h3>Version Information</h3>

<hr>

<p>In this tutorial I&#39;ll be using <a href="http://d3kbcqa49mib13.cloudfront.net/spark-1.1.1.tgz">Spark 1.1.1</a>. I&#39;ll also assume that you&#39;re on some sort of Unix system.</p>

<p>It&#39;s important to note that I&#39;ll be focusing on PySpark and you can check out the (<a href="https://spark.apache.org/docs/latest/api/python/index.html">documentation</a>) for the code examples.</p>

<h3>Download</h3>

<hr>

<p>Go ahead and download <a href="http://d3kbcqa49mib13.cloudfront.net/spark-1.1.1.tgz">Spark 1.1.1</a> right here.</p>

<p>You can download other versions of <a href="https://spark.apache.org/downloads.html">Apache Spark on the site.</a> </p>

<p><img src="/assets/spark-logo.png" alt="Apache Spark"></p>

<h3>The Basics</h3>

<hr>

<p>Once we&#39;ve got Spark downloaded, let&#39;s get started. You&#39;re going to have to build Spark yourself once you&#39;ve downloaded it but as the readme will show you, it&#39;s pretty straight forward. Just run <code>./sbt/sbt assembly</code> in the root download folder directory. It may take a while to build (took me 15+ minutes from scratch) but just be patient. I&#39;d grab a cup of coffee.</p>

<p>Once it&#39;s all built, you should be ready to go. Let&#39;s dive right into the <code>PySpark</code> shell with <code>./bin/pyspark</code> on the command line.</p>

<p>You should see some log information then boom you&#39;ll be in the Spark Shell.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">Welcome</span> <span class="n">to</span>
      <span class="n">____</span>              <span class="n">__</span>
     <span class="o">/</span> <span class="n">__</span><span class="o">/</span><span class="n">__</span>  <span class="n">___</span> <span class="n">_____</span><span class="o">/</span> <span class="o">/</span><span class="n">__</span>
    <span class="n">_</span>\ \<span class="o">/</span> <span class="n">_</span> \<span class="o">/</span> <span class="n">_</span> <span class="err">`</span><span class="o">/</span> <span class="n">__</span><span class="o">/</span>  <span class="s">&#39;_/</span>
   <span class="o">/</span><span class="n">__</span> <span class="o">/</span> <span class="o">.</span><span class="n">__</span><span class="o">/</span>\<span class="n">_</span><span class="p">,</span><span class="n">_</span><span class="o">/</span><span class="n">_</span><span class="o">/</span> <span class="o">/</span><span class="n">_</span><span class="o">/</span>\<span class="n">_</span>\   <span class="n">version</span> <span class="mf">1.1</span><span class="o">.</span><span class="mi">1</span>
      <span class="o">/</span><span class="n">_</span><span class="o">/</span>

<span class="n">Using</span> <span class="n">Python</span> <span class="n">version</span> <span class="mf">2.7</span><span class="o">.</span><span class="mi">6</span> <span class="p">(</span><span class="n">default</span><span class="p">,</span> <span class="n">Sep</span>  <span class="mi">9</span> <span class="mi">2014</span> <span class="mi">15</span><span class="p">:</span><span class="mo">04</span><span class="p">:</span><span class="mi">36</span><span class="p">)</span>
<span class="n">SparkContext</span> <span class="n">available</span> <span class="k">as</span> <span class="n">sc</span><span class="o">.</span>
<span class="o">&gt;&gt;&gt;</span>
</code></pre></div>
<p>On a quick note while I love the regular python shell, I really like the <a href="http://ipython.org/">IPython Shell</a> much better. It&#39;s got tons of handy tools built right in and using IPython with PySpark is super easy. Just close out of that Python Shell and set the IPYTHON environmental variable to 1. Run this in your bash shell.</p>
<div class="highlight"><pre><code class="sh language-sh" data-lang="sh"><span class="nb">export </span><span class="nv">IPYTHON</span><span class="o">=</span>1
./bin/pyspark
</code></pre></div>
<p>Now we&#39;re loaded up into a python shell and we can finally get to work! Now the python shell we&#39;re in is the same python shell that you have on your machine. We can import libraries, do math, same &#39;ol stuff.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="mi">1</span> <span class="o">+</span> <span class="mi">1</span>
<span class="c"># 2</span>
<span class="n">x</span> <span class="o">=</span> <span class="mi">5</span>
<span class="n">x</span>
<span class="c"># 5</span>
</code></pre></div>
<p>There is however, one difference, the <code>sc</code> variable or SparkContext. You can see this is what was made available when we started up the shell previously.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="nb">type</span><span class="p">(</span><span class="n">sc</span><span class="p">)</span>
<span class="c"># pyspark.context.SparkContext</span>
</code></pre></div>
<p>This spark context is the source for all of our handy Spark features. </p>

<p>Let&#39;s go ahead and get started analyzing some data so we can better understand the SparkContext. Let&#39;s start small to understand the concepts. I&#39;ll be using <a href="https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews">the Rotten Tomatoes Dataset from Kaggle</a>. Go ahead and download it and put it in the same Spark download folder on your machine. </p>

<p>Now, let&#39;s go ahead and open it on up and get things started. We load in data with the <code>sc.textFile(&#39;file/path&#39;)</code></p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">data</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">textFile</span><span class="p">(</span><span class="s">&#39;../rotten_tomatoes_train.tsv&#39;</span><span class="p">)</span>
<span class="nb">type</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="c"># pyspark.rdd.RDD</span>
</code></pre></div>
<p>Our dataset is now loaded into spark as an <strong>RDD</strong> or <strong>Resilient Distributed Dataset</strong>. This is the fundamental abstraction in Spark and basically it is a representation of a dataset that is distributed through the cluster. <em>Obviously at this point we don&#39;t have a cluster running as we are just on our local machine but the same concepts apply.</em> </p>

<p>One of the most important concepts concerning RDDs is that they are immutable. What you&#39;re doing is applying a series of <code>transformations</code> to data (stored in the RDD) then finally performing an <code>action</code> in order to get an answer. </p>

<p><em>Just as a note, our columns are tab separated and arranged as follows:</em></p>

<p><em>PhraseId   SentenceId Phrase Sentiment</em></p>

<p>First let&#39;s get the count, how many items(lines) do we have in our data? This is an example of an <code>action</code></p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">data</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="c"># ...log statements</span>
<span class="c"># 156061</span>
</code></pre></div>
<p>There we get an answer because we&#39;re requesting an <code>action</code> as opposed to a <code>transformation</code>. Let&#39;s perform one of those now.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">negative_reviews</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="s">&#39;0&#39;</span> <span class="o">==</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)[</span><span class="mi">3</span><span class="p">])</span>
<span class="k">print</span> <span class="n">negative_reviews</span>
<span class="c"># PythonRDD[14] at RDD at PythonRDD.scala:43</span>
<span class="k">print</span> <span class="nb">type</span><span class="p">(</span><span class="n">negative_reviews</span><span class="p">)</span>
<span class="c"># &lt;class &#39;pyspark.rdd.PipelinedRDD&#39;&gt;</span>
</code></pre></div>
<p>Notice how when we go to print it, it prints out that it is an RDD and that the type is a <code>PipelinedRDD</code> not a list of values as we might expect. That&#39;s because we haven&#39;t performed an <code>action</code> yet, we&#39;ve only performed a <code>transformation</code>.</p>

<p>As a side note, we could write the above code this way as well.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">negative_reviews</span> <span class="o">=</span> <span class="n">data</span> \
                    <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">))</span> \
                    <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="o">==</span> <span class="s">&#39;0&#39;</span><span class="p">)</span>
</code></pre></div>
<p>You&#39;ll notice that when we run <code>transformation</code> commands, nothing gets printed out. That&#39;s because Spark commands are <strong>lazily evaluated</strong>. We set up a <code>transformation</code> from RDD to RDD to prepare to run an <code>action</code> to get back results.</p>

<p>Here are some examples of other <code>actions</code>:</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">negative_reviews</span><span class="o">.</span><span class="n">count</span><span class="p">()</span>
<span class="c"># 7072</span>
<span class="n">negative_reviews</span><span class="o">.</span><span class="n">first</span><span class="p">()</span>
<span class="c"># [u&#39;102&#39;, u&#39;3&#39;, u&#39;would have a hard time sitting through this one&#39;, u&#39;0&#39;]</span>
</code></pre></div>
<p>Now that we&#39;ve got a better idea about how Spark works and executes commands through <code>transformations</code> and <code>actions</code> let&#39;s write ourselves a little MapReduce job to figure out what words show up most commonly in the negative reviews.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">word_counts</span> <span class="o">=</span> <span class="n">negative_reviews</span> \
                <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> \
                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> \
                <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">:</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>
</code></pre></div>
<p>What we&#39;re doing above is getting the word counts. We do that by tokenizing the review text in a <code>flatMap</code> which basically just makes it into one big giant list of words. Then we map each word to 1 and <code>reduceByKey</code> which parallelizes our reduce operation to each key in our data set.</p>

<p>The above code is equivalent to:</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">word_counts</span> <span class="o">=</span> <span class="n">negative_reviews</span> \
                <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> \
                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">word</span><span class="p">:</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span> \
                <span class="o">.</span><span class="n">groupByKey</span><span class="p">()</span> \
                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">val</span><span class="p">:</span> <span class="p">(</span><span class="n">val</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">len</span><span class="p">(</span><span class="n">val</span><span class="p">[</span><span class="mi">1</span><span class="p">])))</span> <span class="c"># basically the value and the generator</span>
</code></pre></div>
<p>Now let&#39;s get the most common word we can find in the reviews.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="k">def</span> <span class="nf">most_common</span><span class="p">(</span><span class="n">comp1</span><span class="p">,</span> <span class="n">comp2</span><span class="p">):</span>
    <span class="n">word1</span><span class="p">,</span> <span class="n">count1</span> <span class="o">=</span> <span class="n">comp1</span>
    <span class="n">word2</span><span class="p">,</span> <span class="n">count2</span> <span class="o">=</span> <span class="n">comp2</span>
    <span class="k">if</span> <span class="n">count1</span> <span class="o">&gt;</span> <span class="n">count2</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">word1</span><span class="p">,</span> <span class="n">count1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">word2</span><span class="p">,</span> <span class="n">count2</span><span class="p">)</span>

<span class="n">most_common_word</span> <span class="o">=</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">most_common</span><span class="p">)</span>
<span class="k">print</span> <span class="n">most_common_word</span>
<span class="c"># (u&#39;,&#39;, 3722)</span>
</code></pre></div>
<p>Knowing that it is a comma isn&#39;t too useful, let&#39;s try it without punctuation, which means rewriting our map function.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="kn">import</span> <span class="nn">string</span>
<span class="k">def</span> <span class="nf">clean_words</span><span class="p">(</span><span class="n">word</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">word</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">word</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>

<span class="n">word_counts</span> <span class="o">=</span> <span class="n">negative_reviews</span> \
                <span class="o">.</span><span class="n">flatMap</span><span class="p">(</span><span class="k">lambda</span> <span class="n">line</span><span class="p">:</span> <span class="n">line</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span><span class="o">.</span><span class="n">split</span><span class="p">())</span> \
                <span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">clean_words</span><span class="p">)</span> \
                <span class="o">.</span><span class="n">reduceByKey</span><span class="p">(</span><span class="k">lambda</span> <span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">:</span> <span class="n">a</span><span class="o">+</span><span class="n">b</span><span class="p">)</span>

<span class="n">most_common_word</span> <span class="o">=</span> <span class="n">word_counts</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">most_common</span><span class="p">)</span>
<span class="k">print</span> <span class="n">most_common_word</span>
<span class="c"># (u&#39;the&#39;, 3070)</span>
</code></pre></div>
<p>Now that&#39;s not particularly useful either so let&#39;s try getting just the top 5. We&#39;ll keep using the word_counts that excludes punctuation.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">word_counts</span><span class="o">.</span><span class="n">sortBy</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*-</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
<span class="c"># (u&#39;the&#39;, 3070), (u&#39;a&#39;, 2572), (u&#39;and&#39;, 2507), (u&#39;of&#39;, 2236), (u&#39;to&#39;, 1880)]</span>
</code></pre></div>
<p>Note how we had to multiply it by negative one in order to sort it least to greatest.</p>

<p>Finally now that we&#39;ve performed some analysis. We might want to store those <code>word_counts</code> for some later use. Speaking of which, it&#39;d also be valuable to store the <code>negative_reviews</code> too. It&#39;s helpful to imagine this being a much larger dataset as this is a trivial example but let&#39;s go ahead and save it.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">negative_reviews</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">(</span><span class="s">&#39;negative_reviews&#39;</span><span class="p">)</span>
<span class="n">word_counts</span><span class="o">.</span><span class="n">saveAsSequenceFile</span><span class="p">(</span><span class="s">&#39;word_counts_negative_reviews&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Note that negative reviews is saved as a Hadoop text file while word counts is saved as a sequence file. Because these datasets are typically large, we have to save them as these distributed data files. Here&#39;s a list of some of the ways you can save these files.</p>
<div class="highlight"><pre><code class="py language-py" data-lang="py"><span class="n">data</span><span class="o">.</span><span class="n">saveAsHadoopDataset</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsNewAPIHadoopFile</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsTextFile</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsHadoopFile</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsPickleFile</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsNewAPIHadoopDataset</span><span class="p">()</span>
<span class="n">data</span><span class="o">.</span><span class="n">saveAsSequenceFile</span><span class="p">()</span>
</code></pre></div>
<p>Those are the basics for how to analyze data in Spark. In some later posts I&#39;ll be going over how to analyze larger sets of data. Going over how to run MapReduce jobs on Spark, using SparkSQL and more.</p>

      </article>
   </div>
</div>

              <div class="footer">
   <!-- <h1>The Portfolio & Writings of Bill Chambers</h1> -->
   <!-- <h3>Internal Navigation</h3> -->
   <div class="row">
      <div class="one offset-by-two columns nav-blocks">
         <a onmouseover="vis_on('fhm');" onmouseout="vis_off('fhm');" href="/"><i class="mdi mdi-home"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fab');" onmouseout="vis_off('fab');" href="/about.html"><i class="mdi mdi-account"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fes');" onmouseout="vis_off('fes');" href="/essays.html"><i class="mdi mdi-file-document"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fpr');" onmouseout="vis_off('fpr');" href="/projects.html"><i class="mdi mdi-beaker"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftu');" onmouseout="vis_off('ftu');" href="/tutorials.html"><i class="mdi mdi-cog"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fli');" onmouseout="vis_off('fli');" href="https://www.linkedin.com/in/wachambers"><i class="mdi mdi-linkedin"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fgh');" onmouseout="vis_off('fgh');" href="http://github.com/anabranch/"><i class="mdi mdi-github-box"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftw');" onmouseout="vis_off('ftw');" href="http://twitter.com/b_a_chambers/"><i class="mdi mdi-twitter-box"></i></a>
      </div>
   </div>
   <div class="row">
      <div class="one offset-by-two columns nav-blocks">
         <a onmouseover="vis_on('fhm');" onmouseout="vis_off('fhm');" id='fhm' class='sibling' href="/">home</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fab');" onmouseout="vis_off('fab');" id='fab' class='sibling' href="/about.html">about</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fes');" onmouseout="vis_off('fes');" id='fes' class='sibling' href="/essays.html">essays</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fpr');" onmouseout="vis_off('fpr');" id='fpr' class='sibling' href="/projects.html">projects</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftu');" onmouseout="vis_off('ftu');" id='ftu' class='sibling' href="/tutorials.html">tutorials</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fli');" onmouseout="vis_off('fli');" id='fli' class='sibling' href="https://www.linkedin.com/in/wachambers">linkedin</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fgh');" onmouseout="vis_off('fgh');" id='fgh' class='sibling' href="http://github.com/anabranch/">github</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftw');" onmouseout="vis_off('ftw');" id='ftw' class='sibling' href="http://twitter.com/b_a_chambers/">twitter</a>
      </div>
   </div>
</div>

        </div> <!-- /container -->
    </body>
    
<script charset="utf-8">
var hovered_el;
function vis_on(id) {
    var e = document.getElementById(id);
        e.style.display = 'block';
    var siblings = document.getElementsByClassName("sibling");
    hovered_el = e;
    for (var i = 0; i < siblings.length; i++) {
        if (siblings[i].id !== id) {
            siblings[i].style.display = 'none';
        }
    }
}

function vis_off(id) {
    hovered_el = undefined;
    setTimeout(function(){
        if (hovered_el == undefined) {
            var e = document.getElementById(id);
                e.style.display = 'none';
        }
    }, 400);
}

setTimeout(function(){
["hhm","hab","hes","hpr","htu","hem", 'fhm', 'fab', 'fes', 'fpr', 'ftu', 'fli', 'fgh', 'ftw'].map(vis_off)
}, 1000);

</script>

</html>
