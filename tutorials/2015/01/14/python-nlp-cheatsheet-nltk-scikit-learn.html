<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <title>Python NLP - NLTK and scikit-learn</title>
        <meta name="viewport" content="width=device-width">
        <link rel="stylesheet" href="/css/normalize.css">
        <link rel="stylesheet" href="/css/skeleton.css">

        <!-- syntax highlighting CSS -->
        <link rel="stylesheet" href="/css/github.css">

        <!-- Custom CSS -->
        <link rel="stylesheet" href="/css/main.css">

    </head>
    <body>

        <div class="container">
              <div class="row">
   <div class="twelve columns personal-intro" style="height:10px;">
   </div>
</div>
<div class="row">
   <div class="one offset-by-three columns nav-blocks">
      <a onmouseover="vis_on('hhm');" onmouseout="vis_off('hhm');" href="/"><i class="mdi mdi-home"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hab');" onmouseout="vis_off('hab');" href="/about.html"><i class="mdi mdi-account"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hes');" onmouseout="vis_off('hes');" href="/essays.html"><i class="mdi mdi-file-document"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hpr');" onmouseout="vis_off('hpr');" href="/projects.html"><i class="mdi mdi-beaker"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('htu');" onmouseout="vis_off('htu');" href="/tutorials.html"><i class="mdi mdi-cog"></i></a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hem');" onmouseout="vis_off('hem');" href="mailto:wchambers@ischool.berkeley.edu"><i class="mdi mdi-email"></i></a>
   </div>
</div>
<div class="row">
   <div class="one offset-by-three columns nav-blocks">
      <a onmouseover="vis_on('hhm');" onmouseout="vis_off('hhm');" id='hhm' class='sibling' href="/">home</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hab');" onmouseout="vis_off('hab');" id='hab' class='sibling' href="/about.html">about</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hes');" onmouseout="vis_off('hes');" id='hes' class='sibling' href="/essays.html">essays</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hpr');" onmouseout="vis_off('hpr');" id='hpr' class='sibling' href="/projects.html">projects</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('htu');" onmouseout="vis_off('htu');" id='htu' class='sibling' href="/tutorials.html">tutorials</a>
   </div>
   <div class="one columns nav-blocks">
      <a onmouseover="vis_on('hem');" onmouseout="vis_off('hem');" id='hem' class='sibling' href="mailto:wchambers@ischool.berkeley.edu">email</a>
   </div>
</div>

              <div class="row">
   <div class="ten offset-by-one columns">
      <article class="post">
         <div class='titles'>
            <h4>Python NLP - NLTK and scikit-learn</h4>
            <p class="meta">
               <!-- <span class='tags'>
                  Tags:
                  
                  
                  </span> -->
               <span class='date'>
               14 January 2015
               </span>
            </p>
         </div>
         <p>This post is meant as a summary of many of the concepts that I learned in <a href="http://people.ischool.berkeley.edu/%7Ehearst/">Marti Hearst&#39;s</a> <a href="http://www.ischool.berkeley.edu/courses/i256">Natural Language Processing</a> class at the <a href="http://www.ischool.berkeley.edu/">UC Berkeley School of Information</a>. I wanted to record the concepts and approaches that I had learned with quick overviews of the code you need to get it working. I figured that it could help some other people get a handle on the goals and code to get things done.</p>

<p><a href="http://www.nltk.org/book_1ed/"><img src="/assets/nlp_processing.gif" alt="Natural Language Processing with Python"></a></p>

<p>I would encourage anyone else to take a look at the <a href="http://www.nltk.org/book_1ed/">Natural Language Processing with Python</a> and read more about scikit-learn.</p>

<h4>Tokenization</h4>

<p>The goal of tokenization is to break up a sentence or paragraph into specific tokens or words. We basically want to convert human language into a more abstract representation that computers can work with.</p>

<p>Sometimes you want to split sentence by sentence and other times you just want to split words.</p>

<p><strong>Sentence Tokenizers</strong></p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">sent_tokenizer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s">&#39;tokenizers/punkt/english.pickle&#39;</span><span class="p">)</span>
</code></pre></div>
<p>Here&#39;s a popular word regular expression tokenizer from the NLTK book that works quite well.</p>

<p><strong>Word Tokenizers</strong></p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">tokenization_pattern</span> <span class="o">=</span> <span class="s">r&#39;&#39;&#39;(?x)    # set flag to allow verbose regexps</span>
<span class="s">([A-Z]\.)+        # abbreviations, e.g. U.S.A.</span>
<span class="s">| \w+(-\w+)*        # words with optional internal hyphens</span>
<span class="s">| \$?\d+(\.\d+)?%?  # currency and percentages, e.g. $12.40, 82%</span>
<span class="s">| \w+[\x90-\xff]  # these are escaped emojis</span>
<span class="s">| [][.,;&quot;&#39;?():-_`]  # these are separate tokens</span>
<span class="s">&#39;&#39;&#39;</span>
<span class="n">word_tokenizer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">tokenize</span><span class="o">.</span><span class="n">regexp</span><span class="o">.</span><span class="n">RegexpTokenizer</span><span class="p">(</span><span class="n">tokenization_pattern</span><span class="p">)</span>
</code></pre></div>
<h4>Part of Speech Tagging</h4>

<p>Once you&#39;ve tokenized the sentences you need to tag them. Tagging is not necessary for all purposes but it does help the computer better understand the objects and references in your sentences. Remember our goal is to encode semantics, not words, and tagging can help us do that.</p>

<p>Unfortunately, this is an imperfect science, it&#39;s just never going to work out perfectly because in so many sentences there are so many different representations of text. Let me show you what I mean, I&#39;ll be using a comical example of a <a href="http://en.wikipedia.org/wiki/Garden_path_sentence">garden path sentence.</a></p>

<p><img src="/assets/discovery-crash-blossom-headline-death-happens-more-slowly-than-thought.jpg" alt="garden path sentence"></p>

<p>This sentence is comical because death can either happen more slowly than thought (as in we had an expectation of death happening at a certain rate of speed).</p>

<p>But semantically, the speed of death can compared to the speed of thought which is obviously strange. Once you learn about these kinds of comical sentence structures, you start to seem them more often.</p>

<p><img src="/assets/stan-carey-crash-blossoms-mcdonalds-fries-the-holy-grail-for-potato-farmers1.jpg" alt="garden path sentence"></p>

<p>This one is also comical. In this sentence we&#39;ve got two meanings as well. McDonald&#39;s fries are the holy grail for potato farmers or more comically McDonald&#39;s <em>fries</em> the actual holy grail for potato farmers. A comical mental image.</p>

<p><em>images from <a href="https://stancarey.wordpress.com/">Sentence first</a></em></p>

<p>Thus part of speech tagging is never perfect, because there are so many interpretations.</p>

<p><strong>Built in tagger</strong></p>

<p>This is the built in tagger, the one that NLTK recommends. It&#39;s pretty slow when working on sort of large corpus.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">sentence</span><span class="p">)</span> <span class="c"># tokenized sentence</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">batch_pos_tag</span><span class="p">(</span><span class="n">sentences</span><span class="p">)</span> <span class="c"># for lots of tokenized sentences</span>
</code></pre></div>
<p><strong>Unigram, Bigram, and Backoff Tagging</strong></p>

<p>These are backoff taggers, basically it&#39;s just a dictionary look up to tag parts of speech. You train it on a tagged corpus(or corpora) and then use it to tag sentences in the future.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">default_tagger</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">DefaultTagger</span><span class="p">(</span><span class="s">&#39;NN&#39;</span><span class="p">)</span>
<span class="n">raw</span> <span class="o">=</span> <span class="s">r&#39;&#39;&#39;what will this silly tagger do?&#39;&#39;&#39;</span>
<span class="n">tokens</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">word_tokenize</span><span class="p">(</span><span class="n">raw</span><span class="p">)</span>
<span class="k">print</span> <span class="n">default_tagger</span><span class="o">.</span><span class="n">tag</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
<span class="c"># [(&#39;what&#39;, &#39;NN&#39;), (&#39;will&#39;, &#39;NN&#39;), (&#39;this&#39;, &#39;NN&#39;), (&#39;silly&#39;, &#39;NN&#39;), (&#39;tagger&#39;, &#39;NN&#39;), (&#39;do&#39;, &#39;NN&#39;), (&#39;?&#39;, &#39;NN&#39;)]</span>
</code></pre></div>
<p>Here&#39;s how you train the tagger on brown, this is a unigram tagger, so it&#39;s not going to perform really well because it will tag everything as a NN (noun) or whatever part of speech we give it.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">brown</span>
<span class="n">brown_tagged_sents</span> <span class="o">=</span> <span class="n">brown</span><span class="o">.</span><span class="n">tagged_sents</span><span class="p">()</span>
<span class="n">unigram_tagger</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">UnigramTagger</span><span class="p">(</span><span class="n">brown_tagged_sents</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;</span><span class="si">%0.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">unigram_tagger</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_sents</span><span class="p">)</span> <span class="c"># eval the tagger</span>
</code></pre></div>
<p>This is a true backoff tagger that defaults to a certain part of speech. So it will look for trigram occurrences and see if it finds any with a certain word formation, if it does not then it will <em>backoff</em> to the bigram tagger, etc.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">build_backoff_tagger</span><span class="p">(</span><span class="n">train_sents</span><span class="p">):</span>
    <span class="n">t0</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">DefaultTagger</span><span class="p">(</span><span class="s">&#39;NN&#39;</span><span class="p">)</span>
    <span class="n">t1</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">UnigramTagger</span><span class="p">(</span><span class="n">train_sents</span><span class="p">,</span> <span class="n">backoff</span><span class="o">=</span><span class="n">t0</span><span class="p">)</span>
    <span class="n">t2</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">BigramTagger</span><span class="p">(</span><span class="n">train_sents</span><span class="p">,</span> <span class="n">backoff</span><span class="o">=</span><span class="n">t1</span><span class="p">)</span>
    <span class="n">t3</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">TrigramTagger</span><span class="p">(</span><span class="n">train_sents</span><span class="p">,</span> <span class="n">backoff</span><span class="o">=</span><span class="n">t2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">t3</span>
<span class="n">ngram_tagger</span> <span class="o">=</span> <span class="n">build_backoff_tagger</span><span class="p">(</span><span class="n">train_sents</span><span class="p">)</span>
</code></pre></div>
<p>What&#39;s nice is to speed things up, you can actually just pickle the backoff tagger so that it&#39;s easier to deploy a tagger if need be.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">pickle</span> <span class="c"># or cPickle</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;pickled_file.pickle&#39;</span><span class="p">,</span> <span class="s">&#39;wb&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">pickle</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">ngram_tagger</span><span class="p">,</span> <span class="n">f</span><span class="p">)</span>
</code></pre></div><div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s">&#39;pickled_file.pickle&#39;</span><span class="p">,</span> <span class="s">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">tagger</span> <span class="o">=</span> <span class="n">pickle</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">f</span><span class="p">)</span>
</code></pre></div>
<h4>Removing Punctuation</h4>

<p>At times you&#39;ll need to remove certain punctuation marks - this is an easy way to do so.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">string</span>
<span class="n">nopunct</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text</span> <span class="k">if</span> <span class="n">w</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">punctuation</span><span class="p">]</span>
<span class="s">&#39; &#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">nopunct</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">100</span><span class="p">])</span>
</code></pre></div>
<h4>Stopwords</h4>

<p>Here&#39;s an easy way to remove stop words.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">normalized</span> <span class="o">=</span> <span class="p">[</span><span class="n">w</span> <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="n">text6</span> <span class="k">if</span> <span class="n">w</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">stopwords</span><span class="o">.</span><span class="n">words</span><span class="p">(</span><span class="s">&#39;english&#39;</span><span class="p">)]</span>
</code></pre></div>
<p>Extend it with:</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">nltk.corpus</span> <span class="kn">import</span> <span class="n">stopwords</span>
<span class="n">my_stops</span> <span class="o">=</span> <span class="n">stopwords</span>
<span class="n">my_stops</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s">&quot;shoebox&quot;</span><span class="p">)</span>
</code></pre></div>
<h4>Stemming</h4>

<p>Stemming the process by which endings are removed from words in order to remove things like tense or plurality. It&#39;s not appropriate for all cases but can make it easier to connect together tenses to see if you&#39;re covering the same subject matter.</p>

<p><a href="http://youtu.be/9Zag7uhjdYo?t=30m00s">Ben Hamner mentions in his Machine Learning Best practices that Kaggle has learned from their competitions that the Porter stemmer is consistently used in winning NLP algorithms for their competitions.</a></p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">pstemmer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">PorterStemmer</span><span class="p">()</span>
<span class="n">lstemmer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">LancasterStemmer</span><span class="p">()</span>
<span class="n">wnlemmatizer</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">WordNetLemmatizer</span><span class="p">()</span>
</code></pre></div>
<h4>Frequency Distributions</h4>

<p>A common go to to see what&#39;s going on with certain text data sets, frequency distributions allow you to see the frequency at which certain words occur and plot it if need be.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">fd</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">FreqDist</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
<span class="n">fd</span><span class="o">.</span><span class="n">plot</span><span class="p">()</span>
<span class="n">fd</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">cumulative</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">fd</span><span class="o">.</span><span class="n">most_common</span><span class="p">(</span><span class="mi">12</span><span class="p">)</span>
</code></pre></div>
<h4>Collocations, Bigrams, Trigrams</h4>

<p>Bigrams and trigrams are just words that are commonly found together and measures their relevance by a certain measurement.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">bigram_measures</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">collocations</span><span class="o">.</span><span class="n">BigramAssocMeasures</span><span class="p">()</span>
<span class="n">trigram_measures</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">collocations</span><span class="o">.</span><span class="n">TrigramAssocMeasures</span><span class="p">()</span>
<span class="n">finder</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">collocations</span><span class="o">.</span><span class="n">BigramCollocationFinder</span><span class="o">.</span><span class="n">from_words</span><span class="p">(</span><span class="n">text</span><span class="p">)</span>
<span class="n">finder</span><span class="o">.</span><span class="n">nbest</span><span class="p">(</span><span class="n">bigram_measures</span><span class="o">.</span><span class="n">pmi</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
</code></pre></div>
<h4>Chunking</h4>

<p>Chunking basically just grabs chunks of text that might be more meaningful to your research or program. You create a list of parts of speech and run that over your corpus. It will extract the phrasing that you need.</p>

<p>Remember you&#39;ve got to customize it to the part of speech tagger that you&#39;re using, like Brown or the Stanford Tagger.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">technical_term</span> <span class="o">=</span> <span class="s">r&quot;T: {&lt;(JJ|NN|NNS|NNP|NNPS)&gt;+&lt;(NN|NNS|NNP|NNPS|CD)&gt;|&lt;(NN|NNS|NNP|NNPS)&gt;}&quot;</span>
<span class="n">cp</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">RegexpParser</span><span class="p">(</span><span class="n">technical_term</span><span class="p">)</span>

<span class="k">for</span> <span class="n">count</span><span class="p">,</span> <span class="n">sent</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">brown</span><span class="o">.</span><span class="n">sents</span><span class="p">()[</span><span class="mi">100</span><span class="p">:</span><span class="mi">104</span><span class="p">]):</span>
    <span class="k">print</span> <span class="s">&quot;Sentence #&quot;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">count</span><span class="p">)</span> <span class="o">+</span> <span class="s">&quot;:&quot;</span>
    <span class="n">parsed</span> <span class="o">=</span> <span class="n">cp</span><span class="o">.</span><span class="n">parse</span><span class="p">(</span><span class="n">nltk</span><span class="o">.</span><span class="n">pos_tag</span><span class="p">(</span><span class="n">sent</span><span class="p">))</span>
    <span class="k">print</span> <span class="n">parsed</span>
    <span class="k">print</span> <span class="s">&quot;</span><span class="se">\n</span><span class="s">Technical Terms:</span><span class="se">\n</span><span class="s">&quot;</span>
    <span class="k">for</span> <span class="n">tree</span> <span class="ow">in</span> <span class="n">parsed</span><span class="o">.</span><span class="n">subtrees</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">tree</span><span class="o">.</span><span class="n">label</span><span class="p">()</span> <span class="o">==</span> <span class="s">&quot;T&quot;</span><span class="p">:</span>
            <span class="k">print</span> <span class="n">tree</span>
</code></pre></div>
<h4>Splitting Training Sets + Test Sets</h4>

<p>This is a simple way that Marti showed us that allows for simple splitting of test sets.</p>

<p>This splits it into thirds.</p>

<p><strong>Train, Dev, Test Sets</strong></p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">create_training_sets_trips</span><span class="p">(</span><span class="n">feature_function</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
    <span class="n">featuresets</span> <span class="o">=</span> <span class="p">[(</span><span class="n">feature_function</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
    <span class="n">third</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">featuresets</span><span class="p">))</span> <span class="o">/</span> <span class="mf">3.0</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">items</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">third</span><span class="p">],</span> <span class="n">items</span><span class="p">[</span><span class="n">third</span><span class="p">:</span><span class="n">third</span><span class="o">*</span><span class="mi">2</span><span class="p">],</span> <span class="n">items</span><span class="p">[</span><span class="n">third</span><span class="o">*</span><span class="mi">2</span><span class="p">:],</span> <span class="n">featuresets</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">third</span><span class="p">],</span> <span class="n">featuresets</span><span class="p">[</span><span class="n">third</span><span class="p">:</span><span class="n">third</span><span class="o">*</span><span class="mi">2</span><span class="p">],</span> <span class="n">featuresets</span><span class="p">[</span><span class="n">third</span><span class="o">*</span><span class="mi">2</span><span class="p">:]</span>

<span class="n">train_items</span><span class="p">,</span> <span class="n">dev_items</span><span class="p">,</span> <span class="n">test_items</span><span class="p">,</span> <span class="n">train_features</span><span class="p">,</span> <span class="n">dev_features</span><span class="p">,</span> <span class="n">test_features</span> <span class="o">=</span> <span class="n">create_training_sets_trips</span><span class="p">(</span><span class="n">f_func</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</code></pre></div>
<p>This splits it into halves.</p>

<p><strong>Simpler Test Sets</strong></p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="k">def</span> <span class="nf">create_training_sets</span><span class="p">(</span><span class="n">feature_function</span><span class="p">,</span> <span class="n">items</span><span class="p">):</span>
    <span class="n">featuresets</span> <span class="o">=</span> <span class="p">[(</span><span class="n">feature_function</span><span class="p">(</span><span class="n">key</span><span class="p">),</span> <span class="n">value</span><span class="p">)</span> <span class="k">for</span> <span class="p">(</span><span class="n">key</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span> <span class="ow">in</span> <span class="n">items</span><span class="p">]</span>
    <span class="n">halfsize</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">featuresets</span><span class="p">))</span> <span class="o">/</span> <span class="mf">2.0</span><span class="p">)</span>
    <span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span> <span class="o">=</span> <span class="n">featuresets</span><span class="p">[</span><span class="n">halfsize</span><span class="p">:],</span> <span class="n">featuresets</span><span class="p">[:</span><span class="n">halfsize</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">train_set</span><span class="p">,</span> <span class="n">test_set</span>
<span class="n">train</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">create_training_sets</span><span class="p">(</span><span class="n">f_func</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</code></pre></div>
<h4>Classifiers &amp; Scikit-learn</h4>

<p><img src="/assets/scikit-learn-logo-small.png" alt="scikit-learn"></p>

<p>Now there are plenty of different ways of classifying text, this isn&#39;t an exhaustive list but it&#39;s a pretty good starting point.</p>

<p><strong>TF-IDF</strong></p>

<p>See my other two posts on TF-IDF here:</p>

<ul>
<li><a href="/tutorials/2014/12/21/tf-idf-explained-in-python.html">TF-IDF explained.</a></li>
<li><a href="/tutorials/2014/12/22/cosine-similarity-explained-in-python.html">TF-IDF and Cosine Similarity explained.</a></li>
</ul>

<p><strong>Naive Bayes Classifiers</strong></p>

<p>This is a simple Naive Bayes classifier.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>

<span class="n">cl</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">NaiveBayesClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_set</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;</span><span class="si">%.3f</span><span class="s">&quot;</span> <span class="o">%</span> <span class="n">nltk</span><span class="o">.</span><span class="n">classify</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">cl</span><span class="p">,</span> <span class="n">test_set</span><span class="p">)</span>
<span class="n">cl</span><span class="o">.</span><span class="n">show_most_informative_features</span><span class="p">(</span><span class="mi">40</span><span class="p">)</span>
<span class="n">cl</span><span class="o">.</span><span class="n">prob_classify</span><span class="p">(</span><span class="n">featurize</span><span class="p">(</span><span class="n">name</span><span class="p">))</span> <span class="c"># get a confidence for the prediction</span>
</code></pre></div>
<p><strong>SVC Classifier</strong></p>

<p>SVMs need numerican inputs, it can take text-based features so you have to convert these features into numbers before passing them to this classifier.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">nltk.classify</span> <span class="kn">import</span> <span class="n">SklearnClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="n">svmc</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">SVC</span><span class="p">(),</span> <span class="n">sparse</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_features</span><span class="p">)</span>
</code></pre></div>
<p><strong>Decision Tree Classification</strong></p>

<p>This is a simple decision tree classifier.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="n">dtc</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">classify</span><span class="o">.</span><span class="n">DecisionTreeClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="n">entropy_cutoff</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">support_cutoff</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  
</code></pre></div>
<p><strong>Maximum Entropy Classifier</strong></p>

<p>A maximum entropy classifier and <a href="http://www.monlp.com/2011/10/10/support-for-scipy-in-nltks-maximum-entropy-methods/">some helpful explainers here</a>.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">scipy</span>

<span class="kn">from</span> <span class="nn">nltk.classify</span> <span class="kn">import</span> <span class="n">maxent</span>
<span class="n">nltk</span><span class="o">.</span><span class="n">classify</span><span class="o">.</span><span class="n">MaxentClassifier</span><span class="o">.</span><span class="n">ALGORITHMS</span>
<span class="c"># [&#39;GIS&#39;,&#39;IIS&#39;,&#39;CG&#39;,&#39;BFGS&#39;,&#39;Powell&#39;,&#39;LBFGSB&#39;,&#39;Nelder-Mead&#39;,&#39;MEGAM&#39;,&#39;TADM&#39;]</span>

<span class="c"># MEGAM or TADM are not rec&#39;d for text classification</span>
<span class="n">mec</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">classify</span><span class="o">.</span><span class="n">MaxentClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_features</span><span class="p">,</span> <span class="s">&#39;GIS&#39;</span><span class="p">,</span> <span class="n">trace</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
</code></pre></div>
<h4>Cross Validating Classifiers</h4>

<p>One thing you&#39;ll need to avoid over-fitting is you&#39;ll want to cross validate with k-folds. This can help you see where you might be over-fitting in your corpus.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">cross_validation</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">cross_validation</span><span class="o">.</span><span class="n">KFold</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_features</span><span class="p">),</span> <span class="n">n_folds</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">indices</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>

<span class="k">for</span> <span class="n">traincv</span><span class="p">,</span> <span class="n">evalcv</span> <span class="ow">in</span> <span class="n">cv</span><span class="p">:</span>
    <span class="n">classifier</span> <span class="o">=</span> <span class="n">nltk</span><span class="o">.</span><span class="n">NaiveBayesClassifier</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_features</span><span class="p">[</span><span class="n">traincv</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">traincv</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">traincv</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
    <span class="k">print</span> <span class="s">&#39;accuracy: </span><span class="si">%.3f</span><span class="s">&#39;</span> <span class="o">%</span> <span class="n">nltk</span><span class="o">.</span><span class="n">classify</span><span class="o">.</span><span class="n">util</span><span class="o">.</span><span class="n">accuracy</span><span class="p">(</span><span class="n">classifier</span><span class="p">,</span> <span class="n">train_features</span><span class="p">[</span><span class="n">evalcv</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">evalcv</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">evalcv</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">]])</span>
</code></pre></div>
<h4>Creating Pipelines for Classifiers</h4>

<p>Finally creating pipelines can help speed things up immensely, especially when you&#39;re moving to more production level code.</p>
<div class="highlight"><pre><code class="language-py" data-lang="py"><span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
<span class="kn">from</span> <span class="nn">nltk.classify.scikitlearn</span> <span class="kn">import</span> <span class="n">SklearnClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfTransformer</span>
<span class="kn">from</span> <span class="nn">sklearn.feature_selection</span> <span class="kn">import</span> <span class="n">SelectKBest</span><span class="p">,</span> <span class="n">chi2</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">MultinomialNB</span>
<span class="kn">from</span> <span class="nn">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">([(</span><span class="s">&#39;tfidf&#39;</span><span class="p">,</span> <span class="n">TfidfTransformer</span><span class="p">()),</span>
                     <span class="p">(</span><span class="s">&#39;chi2&#39;</span><span class="p">,</span> <span class="n">SelectKBest</span><span class="p">(</span><span class="n">chi2</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">2000</span><span class="p">)),</span>
                     <span class="p">(</span><span class="s">&#39;nb&#39;</span><span class="p">,</span> <span class="n">MultinomialNB</span><span class="p">())])</span>
<span class="n">pipecl</span> <span class="o">=</span> <span class="n">SklearnClassifier</span><span class="p">(</span><span class="n">pipeline</span><span class="p">)</span>
<span class="n">pipecl</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">train_features</span><span class="p">)</span>
</code></pre></div>
      </article>
   </div>
</div>

              <div class="footer">
   <!-- <h1>The Portfolio & Writings of Bill Chambers</h1> -->
   <!-- <h3>Internal Navigation</h3> -->
   <div class="row">
      <div class="one offset-by-two columns nav-blocks">
         <a onmouseover="vis_on('fhm');" onmouseout="vis_off('fhm');" href="/"><i class="mdi mdi-home"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fab');" onmouseout="vis_off('fab');" href="/about.html"><i class="mdi mdi-account"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fes');" onmouseout="vis_off('fes');" href="/essays.html"><i class="mdi mdi-file-document"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fpr');" onmouseout="vis_off('fpr');" href="/projects.html"><i class="mdi mdi-beaker"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftu');" onmouseout="vis_off('ftu');" href="/tutorials.html"><i class="mdi mdi-cog"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fli');" onmouseout="vis_off('fli');" href="https://www.linkedin.com/in/wachambers"><i class="mdi mdi-linkedin"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fgh');" onmouseout="vis_off('fgh');" href="http://github.com/anabranch/"><i class="mdi mdi-github-box"></i></a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftw');" onmouseout="vis_off('ftw');" href="http://twitter.com/b_a_chambers/"><i class="mdi mdi-twitter-box"></i></a>
      </div>
   </div>
   <div class="row">
      <div class="one offset-by-two columns nav-blocks">
         <a onmouseover="vis_on('fhm');" onmouseout="vis_off('fhm');" id='fhm' class='sibling' href="/">home</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fab');" onmouseout="vis_off('fab');" id='fab' class='sibling' href="/about.html">about</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fes');" onmouseout="vis_off('fes');" id='fes' class='sibling' href="/essays.html">essays</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fpr');" onmouseout="vis_off('fpr');" id='fpr' class='sibling' href="/projects.html">projects</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftu');" onmouseout="vis_off('ftu');" id='ftu' class='sibling' href="/tutorials.html">tutorials</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fli');" onmouseout="vis_off('fli');" id='fli' class='sibling' href="https://www.linkedin.com/in/wachambers">linkedin</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('fgh');" onmouseout="vis_off('fgh');" id='fgh' class='sibling' href="http://github.com/anabranch/">github</a>
      </div>
      <div class="one columns nav-blocks">
         <a onmouseover="vis_on('ftw');" onmouseout="vis_off('ftw');" id='ftw' class='sibling' href="http://twitter.com/b_a_chambers/">twitter</a>
      </div>
   </div>
</div>

        </div> <!-- /container -->
    </body>

<script charset="utf-8">
var hovered_el;
function vis_on(id) {
    var e = document.getElementById(id);
        e.style.display = 'block';
    var siblings = document.getElementsByClassName("sibling");
    hovered_el = e;
    for (var i = 0; i < siblings.length; i++) {
        if (siblings[i].id !== id) {
            siblings[i].style.display = 'none';
        }
    }
}

function vis_off(id) {
    hovered_el = undefined;
    setTimeout(function(){
        if (hovered_el == undefined) {
            var e = document.getElementById(id);
                e.style.display = 'none';
        }
    }, 400);
}

setTimeout(function(){
["hhm","hab","hes","hpr","htu","hem", 'fhm', 'fab', 'fes', 'fpr', 'ftu', 'fli', 'fgh', 'ftw'].map(vis_off)
}, 1000);

</script>
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-54337529-1', 'auto');
  ga('send', 'pageview');

  </script>
</html>
